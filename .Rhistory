ggplot(data=mtcars, aes(x=fitted, y=residulas, color=vs))+geom_point(size=3)
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=mpg))+geom_point(size=3)
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=mpg))+geom_point(size=3)+geom_smooth()
names(mtcars)
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=hp))+geom_point(size=3)+geom_smooth()
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=drat))+geom_point(size=3)+geom_smooth()
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=qsec))+geom_point(size=3)+geom_smooth()
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=wt))+geom_point(size=3)+geom_smooth()
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=carb))+geom_point(size=3)+geom_smooth()
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=as.factor(carb)))+geom_point(size=3)+geom_smooth()
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=as.factor(carb)))+geom_point(size=3)
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=reidulas))+geom_point(size=3)
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=residulas))+geom_point(size=3)
ggplot(data=mtcars, aes(x=fitted, y=residulas, color=vs))+geom_point(size=3)
library(caret)
library(dplyr)
library(gridExtra)
if (!file.exists("pml-training.csv")){
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv")
}
pml_data<- read.csv("pml-training.csv", header = TRUE, na.strings = c("","NA"))
levels(pml_data$classe)<-c("Correct", "ElbowsFront", "LiftHalf", "LowHalf", "HipsFront")
set.seed(1000)
inTrain = createDataPartition(pml_data$classe, p = 0.6)[[1]]
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
missing <- apply(training, 2, function(x) sum(is.na(x)));
removeColumns <- function(data){
data  = data[,missing==0];
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-1]
}
training <- removeColumns(training)
correlationMatrix <- cor(training[,1:52])
findCorrelation(correlationMatrix, cutoff=0.9)
correlationMatrix <- cor(training[,1:52])
findCorrelation(correlationMatrix, cutoff=0.8)
names(training[,findCorrelation(correlationMatrix, cutoff=0.8)])
names(training[,findCorrelation(correlationMatrix, cutoff=0.9)])
correlationMatrix[,findCorrelation(correlationMatrix, cutoff=0.9)]
correlationMatrix[,findCorrelation(correlationMatrix, cutoff=0.85)]
correlationMatrix[,findCorrelation(correlationMatrix, cutoff=0.9)]
correlationMatrix[,findCorrelation(correlationMatrix, cutoff=-0.9)]
training <- training[,-findCorrelation(correlationMatrix, cutoff=0.9)]
library(doParallel)
registerDoParallel(cores=4)
fit_pca    <- train(training[,-46],training$classe, method="gbm",
trControl = trainControl(method = "cv", number = 5),
preProcess = "pca")
fit_org<- train(training[,-46], training$classe, method="gbm",
trControl = trainControl(method = "cv", number = 5))
fit_scale<- train(training[,-46], training$classe, method="gbm",
trControl = trainControl(method = "cv", number = 5),
preProcess = c("center","scale"))
fit_org$results
fit_pca$results
fit_scale$results
gbmGrid <-  expand.grid(interaction.depth = c(3),
n.trees = c(200),
shrinkage = c(0.5),
n.minobsinnode = 10)
nrow(gbmGrid)
fit_tune<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_scale
gbmGrid <-  expand.grid(interaction.depth = 2,
n.trees = c(200),
shrinkage = c(0.5),
n.minobsinnode = 10)
fit_tune<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
gbmGrid <-  expand.grid(interaction.depth = 2,
n.trees = c(200),
shrinkage = c(0.25),
n.minobsinnode = 10)
fit_tune<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_tune
gbmGrid <-  expand.grid(interaction.depth = c(1,3,5),
n.trees = c(200),
shrinkage = c(0.25,0.1,0.05),
n.minobsinnode = c(5,10,20))
nrow(gbmGrid)
gbmGrid <-  expand.grid(interaction.depth = c(3,5),
n.trees = c(200),
shrinkage = c(0.25,0.1,0.05),
n.minobsinnode = c(5,10,20))
nrow(gbmGrid)
fit_tune<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
library(foreach)
gbmGrid <-  expand.grid(interaction.depth = 3,
n.trees = c(100,150,200,300),
shrinkage = 0.1,
n.minobsinnode = 10)
nrow(gbmGrid)
fit_nTrees<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
library(caret)
library(dplyr)
library(gridExtra)
library(doParallel)
library(gbm)
library(foreach)
fit_nTrees<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_nTrees
gbmGrid <-  expand.grid(interaction.depth = 3,
n.trees = c(100,200,300,400,500),
shrinkage = 0.1,
n.minobsinnode = 10)
fit_nTrees<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_nTrees
gbmGrid <-  expand.grid(interaction.depth = c(1,2,3,4,5),
n.trees = c(200),
shrinkage = 0.1,
n.minobsinnode = 10)
fit_depth<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_depth
gbmGrid <-  expand.grid(interaction.depth = 3,
n.trees = 200,
shrinkage = c(0.25, 0.1, 0.05),
n.minobsinnode = 10)
fit_shrink<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_shrink
gbmGrid <-  expand.grid(interaction.depth = 3,
n.trees = 500,
shrinkage = c(0.25, 0.1, 0.05),
n.minobsinnode = c(5,10,20))
fit_node_500_trees<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid);
gbmGrid <-  expand.grid(interaction.depth = 3,
n.trees = 500,
shrinkage = c(0.25, 0.1, 0.05),
n.minobsinnode = 10)
fit_shrink_n500<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_shrink_n500
# 4. Minimum node size
gbmGrid <-  expand.grid(interaction.depth = 3,
n.trees = 200,
shrinkage = c(0.1),
n.minobsinnode = c(5,10,20))
fit_node<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_node
head(summary(fit_node))
head(summary(fit_shrink))
head(summary(fit_shrink_n500))
fit_node$results
fit_node
kable(fit_node)
library(knitr)
kable(fit_node)
kable(fit_node$results)
kable(c(fit_node$results,fit_shrink$results, fit_shrink_n500$results, fit_nTrees$results, fit_depth$results))
kable(rbind(fit_node$results,fit_shrink$results, fit_shrink_n500$results, fit_nTrees$results, fit_depth$results))
fit_nTrees<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid, verbose=FALSE)
gbmGrid <-  expand.grid(interaction.depth = 3,
n.trees = c(100,200,300,400,500),
shrinkage = 0.1,
n.minobsinnode = 10)
fit_nTrees<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid, verbose=FALSE)
fit_rf <- train(training[,-46], training$classe, method="rf",
trControl = trainControl(method = "cv", number = 5))
names(training)
fit_rf$results
fit_org$results
kable(rbind(fit_node$results,fit_shrink$results, fit_shrink_n500$results, fit_nTrees$results, fit_depth$results))
fit_rf$results
print(fit_rf)
print(fit_rf$finalModel)
print(fit_shrink_n500$finalModel)
ggplot(fit_depth)
ggplot(fit_node)
ggplot(fit_shrink)
ggplot(fit_shrink_n500)
ggplot(fit_nTrees)
ggplot(fit_shrink_n500)
ggplot(fit_shrink)
library(gridExtra)
grid.arrange(g1,g2,g3,g4)
g1 <- ggplot(fit_depth)
g2 <- ggplot(fit_node)
g3 <- ggplot(fit_shrink_n500)
g4 <- ggplot(fit_nTrees)
grid.arrange(g1,g2,g3,g4)
gbmGrid <-  expand.grid(interaction.depth = 5,
n.trees = 500,
shrinkage = 0.25,
n.minobsinnode = 10)
fit_gmb_final<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = gbmGrid)
fit_gmb_final<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
allowParallel=TRUE,
verbose=FALSE,
tuneGrid = gbmGrid)
fit_gmb_final<- train(training[,-46], training$classe,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
verbose=FALSE,
tuneGrid = gbmGrid)
fit_gmb_final
fit_rf
fit_rf$finalModel
fit_gmb_final$finalModel
confusionMatrix(fit_gmb_final)
fit_rf$finalModel
confusionMatrix(fit_gmb_final)
confusionMatrix(fit_gmb_final)
confusionMatrix(fit_rf)
fit_rf
fit_rf$modelInfo
# Make test data to be on same format as training data
testing<-removeColumns(testing)
set.seed(1000)
inTrain = createDataPartition(pml_data$classe, p = 0.6)[[1]]
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
correlationMatrix <- cor(training[,1:52])
correlated <- findCorrelation(correlationMatrix, cutoff=0.9)
is.numeric(training[1,])
sapply(training, is.numeric)
numeric <- sapply(training, is.numeric)
numeric
numerics <- sapply(training, is.numeric)
head(training(numerics))
head(training[,numerics])
correlationMatrix <- cor(training[,numerics])
removeColumns <- function(data){
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-1]
}
training <- removeColumns(training)
numerics <- sapply(training, is.numeric)
correlationMatrix <- cor(training[,numerics])
correlated <- findCorrelation(correlationMatrix, cutoff=0.9)
correlated
numerics <- sapply(training, is.numeric)
numerics
correlationMatrix
missing <- apply(training, 2, function(x) sum(is.na(x)));
missing
# remove correlated columns
missing <- apply(training, 2, function(x) sum(is.na(x)));
training  = data[,training==0];
set.seed(1000)
inTrain = createDataPartition(pml_data$classe, p = 0.6)[[1]]
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
removeColumns <- function(data){
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-1]
}
training <- removeColumns(training)
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
removeColumns <- function(data){
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-1]
}
training <- removeColumns(training)
missing <- apply(training, 2, function(x) sum(is.na(x)));
training  = data[,missing==0];
training  = training[,missing==0];
numerics <- sapply(training, is.numeric)
correlationMatrix <- cor(training[,numerics])
correlated <- findCorrelation(correlationMatrix, cutoff=0.9)
training <- training[,-correlated]
testing <- removeColumns(testing)
testing <- testing[,missing==0];
testing <- testing[,-correlated]
predict(fit_gbm_final)
pred_gbm <- predict(fit_gbm_final, newdata=testing)
pred_rf  <- predict(fit_rf, newdata=testing)
fit_gmb_final$results
pred_gbm <- predict(fit_gmb_final, newdata=testing)
pred_rf
mean(pred_rf==testing$classe)
summary(pref$rf)
summary(pref_rf)
summary(pred_rf)
confusionMatrix(pred_rf)
pred_gbm <- predict(fit_gmb_final, newdata=testing)
sapply(testing,class)
?model.matrix
pred_rf
summary(pred_rf)
confusionMatrix(pred_rf)
confusionMatrix(pred_rf, testing$classe)
training[,-46] <- as.numeric(training[,-46])
training.class <- training$classe
training$classe<-NULL;
training$classe
sapply(training,class)
training <- as.numeric(training)
sapply(training,as.numeric)
training<-sapply(training,as.numeric);
sapply(training,class)
size(training)
dim(training)
# 5. Final model
gbmGrid <-  expand.grid(interaction.depth = 5,
n.trees = 500,
shrinkage = 0.25,
n.minobsinnode = 10)
dim(testing)
fit_gmb_final<- train(training, training.class,
method="gbm",
trControl = trainControl(method = "cv", number = 5),
verbose=FALSE,
tuneGrid = gbmGrid)
fit_gmb_final$results
confusionMatrix(fit_gmb_final)
pred_gbm <- predict(fit_gmb_final, newdata=testing)
testing.class <- testing$classe
testing$classe<-NULL;
testing<-sapply(testing,as.numeric);
pred_gbm <- predict(fit_gmb_final, newdata=testing)
confusionMatrix(fit_gmb_fina, testing.class)
confusionMatrix(pred_rf, testing.class)
confusionMatrix(fit_gmb_final, testing.class)
mean(pred_rf==testing.classe)
mean(pred_gbm==testing.classe)
mean(pred_rf==testing.class)
mean(pred_gbm==testing.class)
confusionMatrix(pred_gbm, testing.class)
confusionMatrix(pred_rf, testing.class)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv")
pml_data<- read.csv("pml-testing.csv", header = TRUE, na.strings = c("","NA"))
tests<- read.csv("pml-testing.csv", header = TRUE, na.strings = c("","NA"))
tests
tests.id <- tests$problem_id;
tests$problem_id <- NULL;
tests <- removeColumns(tests)
names(tests)
tests <- tests[,missing]
tests <- tests[,missing==0]
missing==0
names(tests)
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
removeColumns <- function(data){
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-1]
}
training.class <- training$classe
training$classe<-NULL;
missing <- apply(training, 2, function(x) sum(is.na(x)));
training<- training[,missing==0];
numerics <- sapply(training, is.numeric)
correlationMatrix <- cor(training[,numerics])
correlated <- findCorrelation(correlationMatrix, cutoff=0.9)
training <- training[,-correlated]
training<-sapply(training,as.numeric);
training = pml_data[ inTrain,]
names(training)
removeColumns <- function(data){
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-grep("X",names(data))]
}
training <- removeColumns(training)
names(training)
pml_data<- read.csv("pml-training.csv", header = TRUE, na.strings = c("","NA"))
levels(pml_data$classe)<-c("Correct", "ElbowsFront", "LiftHalf", "LowHalf", "HipsFront")
set.seed(1000)
inTrain = createDataPartition(pml_data$classe, p = 0.6)[[1]]
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
removeColumns <- function(data){
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-grep("X",names(data))]
}
training <- removeColumns(training)
training.class <- training$classe
training$classe<-NULL;
names(training)
numerics <- sapply(training, is.numeric)
correlationMatrix <- cor(training[,numerics])
correlated <- findCorrelation(correlationMatrix, cutoff=0.9)
correlated
correlationMatrix
missing <- apply(training, 2, function(x) sum(is.na(x)));
missing
missing==0
training<- training[,missing==0];
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
removeColumns <- function(data){
data <- data[,-grep("timestamp",names(data))]
data <- data[,-grep("window",names(data))]
data <- data[,-grep("user_name",names(data))]
data <- data[,-grep("X",names(data))]
}
training <- removeColumns(training)
training.class <- training$classe
training$classe<-NULL;
missing <- apply(training, 2, function(x) sum(is.na(x)));
training<- training[,missing==0];
numerics <- sapply(training, is.numeric)
correlationMatrix <- cor(training[,numerics])
correlated <- findCorrelation(correlationMatrix, cutoff=0.9)
training <- training[,-correlated]
training<-sapply(training,as.numeric);
testing.class <- testing$classe
testing$classe<-NULL;
testing <- removeColumns(testing)
testing <- testing[,missing==0];
testing <- testing[,-correlated]
testing<-sapply(testing,as.numeric);
tests<- read.csv("pml-testing.csv", header = TRUE, na.strings = c("","NA"))
tests.id <- tests$problem_id;
tests$problem_id <- NULL;
tests <- removeColumns(tests)
tests <- tests[,missing==0]
tests <- tests[,-correlated]
names(training)
names(tests)
set.seed(1000)
inTrain = createDataPartition(pml_data$classe, p = 0.6)[[1]]
training = pml_data[ inTrain,]
testing  = pml_data[-inTrain,]
training <- removeColumns(training)
# remove correlated columns
training.class <- training$classe
training$classe<-NULL;
missing <- apply(training, 2, function(x) sum(is.na(x)));
training<- training[,missing==0];
numerics <- sapply(training, is.numeric)
correlationMatrix <- cor(training[,numerics])
correlated <- findCorrelation(correlationMatrix, cutoff=0.9)
training <- training[,-correlated]
names(training)
names(tests)
tests <- sapply(tests,as.numeric);
pred_submission<- predict(fit_gmb_final, newdata=tests)
pred_submission
c(pred_submission, tests.id)
cbind(pred_submission, tests.id)
levels(pred_submission)<- c("A", "B", "C", "D", "E")
cbind(pred_submission, tests.id)
pred_submission
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
pml_write_files(pred_submission)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(pred_submission)
setwd("~/Coursera/MachineLearning")
pml_write_files(pred_submission)
pred_submission
predict(fit_gmb_final, newdata=tests)
